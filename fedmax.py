# -*- coding: utf-8 -*-
"""fedmax.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ijhLs1uxfeIv4jQJU2jJqrZCc695Mwwv
"""

import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Model, clone_model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Define Model Architecture
def create_model():
    inputs = Input(shape=(128, 128, 3))
    x = Conv2D(32, (3, 3), activation='relu')(inputs)
    x = MaxPooling2D(pool_size=(2, 2))(x)
    x = Conv2D(64, (3, 3), activation='relu')(x)
    x = MaxPooling2D(pool_size=(2, 2))(x)
    x = Flatten()(x)
    x = Dense(128, activation='relu')(x)
    x = Dropout(0.5)(x)
    outputs = Dense(5, activation='softmax')(x)
    model = Model(inputs, outputs)
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    return model

# FedMax Aggregation Function
def fedmax_aggregate(global_model, client_weights, epsilon=1e-6):
    """
    Aggregate client weights using FedMax algorithm.

    :param global_model: The global model to update.
    :param client_weights: List of weights from client models.
    :param epsilon: Small value to avoid division by zero.
    """
    max_differences = [
        np.max(np.abs(np.stack([client_weights[i][layer] for i in range(len(client_weights))])), axis=0)
        for layer in range(len(client_weights[0]))
    ]

    aggregated_weights = []
    for layer in range(len(client_weights[0])):
        aggregated_layer = np.mean(
            [client_weights[i][layer] * max_differences[layer] for i in range(len(client_weights))], axis=0
        )
        aggregated_weights.append(aggregated_layer)

    global_model.set_weights(aggregated_weights)
    return global_model

# Function to Train on Client
def train_on_client(client_model, data_generator, epochs=5):
    """
    Train the model on client data.

    :param client_model: Model to train.
    :param data_generator: Data generator for the client.
    :param epochs: Number of epochs to train.
    :return: Trained client model weights.
    """
    client_model.fit(data_generator, epochs=epochs, verbose=0)
    return client_model.get_weights()

# Federated Learning Simulation
def federated_learning_simulation(global_model, client_data_generators, num_rounds=10, epochs=5):
    global_weights = global_model.get_weights()

    for round_num in range(num_rounds):
        print(f"Round {round_num + 1}/{num_rounds}")

        # Train on each client
        client_weights = []
        for client_idx, client_data_gen in enumerate(client_data_generators):
            print(f"Training on Client {client_idx + 1}")
            client_model = clone_model(global_model)
            client_model.set_weights(global_weights)
            client_weights.append(train_on_client(client_model, client_data_gen, epochs=epochs))

        # Aggregate weights using FedMax
        print("Aggregating weights with FedMax...")
        global_model = fedmax_aggregate(global_model, client_weights)

        # Evaluate global model
        print(f"Evaluating global model after round {round_num + 1}...")
        loss, accuracy = global_model.evaluate(generator_test)
        print(f"Round {round_num + 1} - Loss: {loss}, Accuracy: {accuracy}")

    return global_model

# Data Preparation
datagen_train = ImageDataGenerator(rescale=1.0 / 255)
datagen_test = ImageDataGenerator(rescale=1.0 / 255)

# Split the dataset into multiple clients
client_data_generators = [
    datagen_train.flow_from_directory('path_to_client_1_data', target_size=(128, 128), batch_size=32, class_mode='categorical'),
    datagen_train.flow_from_directory('path_to_client_2_data', target_size=(128, 128), batch_size=32, class_mode='categorical'),
    datagen_train.flow_from_directory('path_to_client_3_data', target_size=(128, 128), batch_size=32, class_mode='categorical'),
    datagen_train.flow_from_directory('path_to_client_4_data', target_size=(128, 128), batch_size=32, class_mode='categorical'),
    datagen_train.flow_from_directory('path_to_client_5_data', target_size=(128, 128), batch_size=32, class_mode='categorical'),
]

generator_test = datagen_test.flow_from_directory('path_to_test_data', target_size=(128, 128), batch_size=32, class_mode='categorical')

# Initialize Global Model
global_model = create_model()

# Simulate Federated Learning
final_model = federated_learning_simulation(global_model, client_data_generators, num_rounds=10, epochs=5)

# Save the Final Model
final_model.save('federated_model_with_fedmax.h5')